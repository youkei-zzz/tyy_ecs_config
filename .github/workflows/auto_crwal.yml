name: Deploy crawler

on:
  workflow_dispatch:
  push:
    branches: [ "main" ]
  schedule:
    # Run every day at 00:00 UTC (08:00 Beijing time)
    - cron: '0 0 * * *'

env:
  CRAWLER_SCRIPT: "å®Œæ•´çˆ¬å–è„šæœ¬.js"

permissions:
  contents: write

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Install pnpm
        uses: pnpm/action-setup@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install

      - name: Install Playwright browsers
        run: npx playwright install --with-deps

      - name: Run crawler
        id: run_crawler
        run: |
          set -o pipefail
          start_time=$(date +%s)
          node "$CRAWLER_SCRIPT" 2>&1 | tee crawl-output.log
          exit_code=${PIPESTATUS[0]}
          end_time=$(date +%s)
          duration=$((end_time - start_time))
          echo "exit_code=$exit_code" >> "$GITHUB_OUTPUT"
          echo "duration=$duration" >> "$GITHUB_OUTPUT"
          exit $exit_code

      - name: Commit and push updated dataset
        if: success()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/ecs-zones-metadata.json data/ecs-zones-simple.json || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "Update ECS zones dataset [skip ci]"
          git push

      - name: Publish dataset to public data repository
        if: success()
        env:
          PUBLIC_DATA_REPO: ${{ secrets.PUBLIC_DATA_REPO }}
          PUBLIC_DATA_BRANCH: ${{ secrets.PUBLIC_DATA_BRANCH }}
          PUBLIC_DATA_PAT: ${{ secrets.PUBLIC_DATA_PAT }}
        run: |
          set -euo pipefail
          if [ -z "${PUBLIC_DATA_REPO:-}" ] || [ -z "${PUBLIC_DATA_PAT:-}" ]; then
            echo "Public dataset secrets missing, skipping publish step."
            exit 0
          fi
          publish_dir="$(mktemp -d)"
          branch="${PUBLIC_DATA_BRANCH:-main}"
          repo_url="https://${PUBLIC_DATA_PAT}@github.com/${PUBLIC_DATA_REPO}.git"
          git clone --depth 1 "$repo_url" "$publish_dir"
          cd "$publish_dir"
          if git ls-remote --exit-code origin "refs/heads/${branch}" >/dev/null 2>&1; then
            git fetch origin "${branch}:${branch}"
            git checkout "$branch"
          else
            git checkout -b "$branch"
          fi
          mkdir -p data
          cp "$GITHUB_WORKSPACE/data/ecs-zones-metadata.json" data/
          cp "$GITHUB_WORKSPACE/data/ecs-zones-simple.json" data/
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/ecs-zones-metadata.json data/ecs-zones-simple.json
          if git diff --cached --quiet; then
            echo "Public dataset already up to date."
            exit 0
          fi
          git commit -m "Update dataset from ${GITHUB_REPOSITORY}@${GITHUB_SHA}"
          git push origin "$branch"
          echo "Public metadata URL: https://raw.githubusercontent.com/${PUBLIC_DATA_REPO}/${branch}/data/ecs-zones-metadata.json"
          echo "Public simple list URL: https://raw.githubusercontent.com/${PUBLIC_DATA_REPO}/${branch}/data/ecs-zones-simple.json"

      - name: Print dataset HTTP URLs
        if: success()
        run: |
          echo "Metadata URL:"
          echo "  https://raw.githubusercontent.com/${{ github.repository }}/main/data/ecs-zones-metadata.json"
          echo "Simple list URL:"
          echo "  https://raw.githubusercontent.com/${{ github.repository }}/main/data/ecs-zones-simple.json"

      - name: Generate execution summary
        id: summary
        if: always()
        run: |
          set -euo pipefail
          exit_code="${{ steps.run_crawler.outputs.exit_code }}"
          duration="${{ steps.run_crawler.outputs.duration }}"
          if [ "$exit_code" == "0" ]; then
            status="æˆåŠŸï¼ŒğŸ˜„"
          else
            status="å¤±è´¥ï¼ŒğŸ˜®"
          fi
          hours=$((duration / 3600))
          minutes=$(((duration % 3600) / 60))
          seconds=$((duration % 60))
          if [ $hours -gt 0 ]; then
            time_str="${hours}h ${minutes}m ${seconds}s"
          elif [ $minutes -gt 0 ]; then
            time_str="${minutes}m ${seconds}s"
          else
            time_str="${seconds}s"
          fi
          cat > summary.txt <<EOF
          ====================================
                    å‚æ•°çˆ¬å–æ‰§è¡ŒæŠ¥å‘Š
          ====================================
          æ‰§è¡Œç»“æœ: ${status}
          æ‰§è¡Œæ—¶é•¿: ${time_str}
          å®Œæˆæ—¶é—´: $(TZ='Asia/Shanghai' date '+%Y-%m-%d %H:%M:%S')

          æ•°æ®æºé“¾æ¥:
          - Metadata: https://raw.githubusercontent.com/${{ github.repository }}/main/data/ecs-zones-metadata.json
          - Simple: https://raw.githubusercontent.com/${{ github.repository }}/main/data/ecs-zones-simple.json
          ====================================
          EOF
          echo "summary_file=summary.txt" >> "$GITHUB_OUTPUT"

      - name: Upload crawler log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: crawl-output
          path: crawl-output.log
          if-no-files-found: ignore

      - name: Resolve sender email
        id: sender
        if: always()
        env:
          SMTP_FROM_SECRET: ${{ secrets.SMTP_FROM }}
          SMTP_USERNAME: ${{ secrets.SMTP_USERNAME }}
        run: |
          resolved="$SMTP_FROM_SECRET"
          if [ -z "$resolved" ]; then
            resolved="$SMTP_USERNAME"
          fi
          if [ -z "$resolved" ]; then
            echo "No SMTP sender available." >&2
            exit 1
          fi
          echo "value=$resolved" >> "$GITHUB_OUTPUT"
          echo "EMAIL_FROM=$resolved" >> "$GITHUB_ENV"

      - name: Resolve SMTP secure mode
        id: smtp_secure
        if: always()
        env:
          SMTP_SECURE_SECRET: ${{ secrets.SMTP_SECURE }}
        run: |
          value="${SMTP_SECURE_SECRET,,}"
          case "$value" in
            ""|"auto"|"default")
              resolved="true"
              ;;
            "true"|"1"|"ssl"|"tls")
              resolved="true"
              ;;
            "false"|"0"|"starttls"|"plain")
              resolved="false"
              ;;
            *)
              resolved="true"
              ;;
          esac
          echo "value=$resolved" >> "$GITHUB_OUTPUT"

      - name: Email crawl report
        if: always()
        uses: dawidd6/action-send-mail@v4
        with:
          server_address: ${{ secrets.SMTP_SERVER }}
          server_port: ${{ secrets.SMTP_PORT }}
          username: ${{ secrets.SMTP_USERNAME }}
          password: ${{ secrets.SMTP_PASSWORD }}
          subject: "è‡ªåŠ¨åŒ–-çˆ¬å–äº‘ä¸»æœºåœ°åŒºå‚æ•°ä¿¡æ¯ - ${{ steps.run_crawler.outputs.exit_code == '0' && 'æˆåŠŸ' || 'å¤±è´¥' }}"
          to: ${{ secrets.NOTIFY_EMAIL }}
          from: ${{ env.EMAIL_FROM }}
          secure: ${{ steps.smtp_secure.outputs.value == 'true' }}
          body: file://summary.txt
